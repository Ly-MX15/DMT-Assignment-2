{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import ndcg_score\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From here it's workable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_scores(row):\n",
    "    if row['booking_bool'] == 1:\n",
    "        return 5\n",
    "    elif row['click_bool'] == 1:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>srch_id</th>\n",
       "      <th>date_time</th>\n",
       "      <th>site_id</th>\n",
       "      <th>visitor_location_country_id</th>\n",
       "      <th>visitor_hist_starrating</th>\n",
       "      <th>visitor_hist_adr_usd</th>\n",
       "      <th>prop_country_id</th>\n",
       "      <th>prop_id</th>\n",
       "      <th>prop_starrating</th>\n",
       "      <th>prop_review_score</th>\n",
       "      <th>...</th>\n",
       "      <th>price_per_adult</th>\n",
       "      <th>price_per_person</th>\n",
       "      <th>prop_historical_price</th>\n",
       "      <th>prop_clicked_prob</th>\n",
       "      <th>child_bool</th>\n",
       "      <th>price_review_ratio</th>\n",
       "      <th>price_starrating_ratio</th>\n",
       "      <th>price_rank_percentile</th>\n",
       "      <th>location1_rank_percentile</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2013-04-04 08:32:15</td>\n",
       "      <td>12</td>\n",
       "      <td>187</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>219</td>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>...</td>\n",
       "      <td>26.1925</td>\n",
       "      <td>26.1925</td>\n",
       "      <td>141.174964</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>29.934286</td>\n",
       "      <td>34.923333</td>\n",
       "      <td>0.429825</td>\n",
       "      <td>0.780702</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2013-04-04 08:32:15</td>\n",
       "      <td>12</td>\n",
       "      <td>187</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>219</td>\n",
       "      <td>10404</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>42.6850</td>\n",
       "      <td>42.6850</td>\n",
       "      <td>152.933013</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>42.685000</td>\n",
       "      <td>42.685000</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.228070</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2013-04-04 08:32:15</td>\n",
       "      <td>12</td>\n",
       "      <td>187</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>219</td>\n",
       "      <td>21315</td>\n",
       "      <td>3</td>\n",
       "      <td>4.5</td>\n",
       "      <td>...</td>\n",
       "      <td>44.9500</td>\n",
       "      <td>44.9500</td>\n",
       "      <td>137.002613</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>39.955556</td>\n",
       "      <td>59.933333</td>\n",
       "      <td>0.859649</td>\n",
       "      <td>0.228070</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2013-04-04 08:32:15</td>\n",
       "      <td>12</td>\n",
       "      <td>187</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>219</td>\n",
       "      <td>27348</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>121.2100</td>\n",
       "      <td>121.2100</td>\n",
       "      <td>80.640419</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>121.210000</td>\n",
       "      <td>242.420000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.780702</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2013-04-04 08:32:15</td>\n",
       "      <td>12</td>\n",
       "      <td>187</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>219</td>\n",
       "      <td>29604</td>\n",
       "      <td>4</td>\n",
       "      <td>3.5</td>\n",
       "      <td>...</td>\n",
       "      <td>35.8950</td>\n",
       "      <td>35.8950</td>\n",
       "      <td>138.379512</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>41.022857</td>\n",
       "      <td>35.895000</td>\n",
       "      <td>0.719298</td>\n",
       "      <td>0.517544</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 76 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   srch_id            date_time  site_id  visitor_location_country_id  \\\n",
       "0        1  2013-04-04 08:32:15       12                          187   \n",
       "1        1  2013-04-04 08:32:15       12                          187   \n",
       "2        1  2013-04-04 08:32:15       12                          187   \n",
       "3        1  2013-04-04 08:32:15       12                          187   \n",
       "4        1  2013-04-04 08:32:15       12                          187   \n",
       "\n",
       "   visitor_hist_starrating  visitor_hist_adr_usd  prop_country_id  prop_id  \\\n",
       "0                      0.0                   0.0              219      893   \n",
       "1                      0.0                   0.0              219    10404   \n",
       "2                      0.0                   0.0              219    21315   \n",
       "3                      0.0                   0.0              219    27348   \n",
       "4                      0.0                   0.0              219    29604   \n",
       "\n",
       "   prop_starrating  prop_review_score  ...  price_per_adult  price_per_person  \\\n",
       "0                3                3.5  ...          26.1925           26.1925   \n",
       "1                4                4.0  ...          42.6850           42.6850   \n",
       "2                3                4.5  ...          44.9500           44.9500   \n",
       "3                2                4.0  ...         121.2100          121.2100   \n",
       "4                4                3.5  ...          35.8950           35.8950   \n",
       "\n",
       "   prop_historical_price  prop_clicked_prob  child_bool  price_review_ratio  \\\n",
       "0             141.174964                0.0       False           29.934286   \n",
       "1             152.933013                0.0       False           42.685000   \n",
       "2             137.002613                0.0       False           39.955556   \n",
       "3              80.640419                0.0       False          121.210000   \n",
       "4             138.379512                0.0       False           41.022857   \n",
       "\n",
       "   price_starrating_ratio  price_rank_percentile  location1_rank_percentile  \\\n",
       "0               34.923333               0.429825                   0.780702   \n",
       "1               42.685000               0.842105                   0.228070   \n",
       "2               59.933333               0.859649                   0.228070   \n",
       "3              242.420000               1.000000                   0.780702   \n",
       "4               35.895000               0.719298                   0.517544   \n",
       "\n",
       "   score  \n",
       "0      0  \n",
       "1      0  \n",
       "2      0  \n",
       "3      0  \n",
       "4      0  \n",
       "\n",
       "[5 rows x 76 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 逐个读取feature_engineered_training_chunk{i}并上下拼接到一个df\n",
    "base_path = '/Users/eva/Documents/Study/Y1S2/DMT/assignment2/'\n",
    "file_pattern = 'best_feature_engineered_training_chunk_{}.csv'\n",
    "for i in range(10):\n",
    "    df_chunk = pd.read_csv(base_path + file_pattern.format(i))\n",
    "    df_chunk['score'] = df_chunk.apply(assign_scores, axis=1)\n",
    "    if i == 0:\n",
    "        df = df_chunk\n",
    "    else:\n",
    "        df = pd.concat([df, df_chunk], axis=0)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 检查df NA 展示有NA的列\n",
    "na_counts = df.isna().sum()\n",
    "\n",
    "# 打印有NA值的列和NA值的数量\n",
    "print(\"Columns with NA values and their counts:\")\n",
    "for col, count in na_counts.items():\n",
    "    if count > 0:\n",
    "        print(f\"{col}: {count}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this isnt needed anymore\n",
    "A = ['visitor_hist_starrating', 'visitor_hist_adr_usd']\n",
    "B = ['_prop_id_']\n",
    "C = ['mean','median']\n",
    "\n",
    "columns_to_drop = [a+b + c for a in A for c in C for b in B]\n",
    "print(\"Columns to drop:\", columns_to_drop)\n",
    "df.drop(columns=columns_to_drop, errors='ignore', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this isnt needed anymore\n",
    "A =['prop_starrating', 'prop_review_score', 'prop_location_score1', \n",
    "            'prop_location_score2', 'price_usd']\n",
    "B = ['_srch_destination_id_']\n",
    "C = ['mean']\n",
    "\n",
    "columns_to_drop = [a+ b + c  for a in A for c in C for b in B]\n",
    "print(\"Columns to drop:\", columns_to_drop)\n",
    "df.drop(columns=columns_to_drop, errors='ignore', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this isnt needed anymore\n",
    "df_feature = pd.read_csv('feature_importance.csv')\n",
    "\n",
    "zero_importance_features = df_feature[df_feature['Importance'] == 0]['Feature'].tolist()\n",
    "print(\"Zero importance features:\", zero_importance_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69\n",
      "76\n"
     ]
    }
   ],
   "source": [
    "columns = df.columns\n",
    "\n",
    "features = [\n",
    "    col for col in columns if col not in ['date_time', 'position', 'click_bool', 'booking_bool', 'score', 'srch_id']\n",
    "    and 'gross_bookings_usd' not in col and 'position' not in col and col != 'price_per_person_rank_percentile'\n",
    "]\n",
    "\n",
    "\n",
    "print(len(features))\n",
    "print(len(df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Default Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_params = {\n",
    "    'objective': 'lambdarank',\n",
    "    'metric': 'ndcg',\n",
    "    'max_depth': 3,\n",
    "    'num_leaves': 28,\n",
    "    'learning_rate': 0.1,\n",
    "    'feature_fraction': 0.8,\n",
    "    'min_child_samples': 40,\n",
    "    'min_child_weight': 0.001,\n",
    "    'bagging_fraction': 1,\n",
    "    'bagging_freq': 2,\n",
    "    'reg_alpha': 0.001,\n",
    "    'reg_lambda': 8,\n",
    "    'cat_smooth': 0,\n",
    "    'num_iterations': 800,\n",
    "    'is_unbalance': True  # 仅当你确信数据不平衡严重且影响模型性能时才设置\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_ids = df['srch_id'].unique()\n",
    "train_ids, test_ids = train_test_split(unique_ids, test_size=0.15, random_state=42, shuffle=True)  # 首先分割出20%为最终测试集\n",
    "train_val_ids, val_ids = train_test_split(train_ids, test_size=0.25, random_state=42, shuffle=True)  # 将剩余80%分为训练集(60%)和验证集(20%)\n",
    "\n",
    "train_df = df[df['srch_id'].isin(train_val_ids)]\n",
    "val_df = df[df['srch_id'].isin(val_ids)]\n",
    "test_df = df[df['srch_id'].isin(test_ids)]\n",
    "\n",
    "train_data = lgb.Dataset(train_df[features], label=train_df['score'], group=train_df['srch_id'].value_counts().sort_index())\n",
    "val_data = lgb.Dataset(val_df[features], label=val_df['score'], group=val_df['srch_id'].value_counts().sort_index())\n",
    "test_data = lgb.Dataset(test_df[features], label=test_df['score'], group=test_df['srch_id'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'num_leaves': 110, 'max_depth': 12, 'min_child_samples': 210, 'learning_rate': 0.1, 'feature_fraction': 0.9, 'bagging_fraction': 0.9, 'bagging_freq': 3, 'reg_alpha': 5, 'reg_lambda': 100, 'num_iterations': 400, 'objective': 'lambdarank', 'metric': 'ndcg', 'ndcg_eval_at': [5], 'verbose': -1, 'boosting_type': 'gbdt', 'feature_pre_filter': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/eva/opt/anaconda3/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[400]\tvalid_0's ndcg@5: 0.405972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/st/hfszkgw55n73h3v2jz7n8xth0000gn/T/ipykernel_52975/2751782417.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df['predictions'] = test_pred\n",
      "/var/folders/st/hfszkgw55n73h3v2jz7n8xth0000gn/T/ipykernel_52975/2751782417.py:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df.sort_values(['srch_id', 'predictions'], ascending=[True, False], inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average NDCG Score: 0.4068791481469258\n",
      "{'num_leaves': 110, 'max_depth': 12, 'min_child_samples': 210, 'learning_rate': 0.1, 'feature_fraction': 0.9, 'bagging_fraction': 0.9, 'bagging_freq': 2, 'reg_alpha': 5, 'reg_lambda': 100, 'num_iterations': 400, 'objective': 'lambdarank', 'metric': 'ndcg', 'ndcg_eval_at': [5], 'verbose': -1, 'boosting_type': 'gbdt', 'feature_pre_filter': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/eva/opt/anaconda3/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[335]\tvalid_0's ndcg@5: 0.405287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/st/hfszkgw55n73h3v2jz7n8xth0000gn/T/ipykernel_52975/2751782417.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df['predictions'] = test_pred\n",
      "/var/folders/st/hfszkgw55n73h3v2jz7n8xth0000gn/T/ipykernel_52975/2751782417.py:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df.sort_values(['srch_id', 'predictions'], ascending=[True, False], inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average NDCG Score: 0.4045852067042149\n",
      "{'num_leaves': 120, 'max_depth': 12, 'min_child_samples': 210, 'learning_rate': 0.1, 'feature_fraction': 0.9, 'bagging_fraction': 0.9, 'bagging_freq': 2, 'reg_alpha': 5, 'reg_lambda': 100, 'num_iterations': 400, 'objective': 'lambdarank', 'metric': 'ndcg', 'ndcg_eval_at': [5], 'verbose': -1, 'boosting_type': 'gbdt', 'feature_pre_filter': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/eva/opt/anaconda3/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[398]\tvalid_0's ndcg@5: 0.40599\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/st/hfszkgw55n73h3v2jz7n8xth0000gn/T/ipykernel_52975/2751782417.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df['predictions'] = test_pred\n",
      "/var/folders/st/hfszkgw55n73h3v2jz7n8xth0000gn/T/ipykernel_52975/2751782417.py:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df.sort_values(['srch_id', 'predictions'], ascending=[True, False], inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average NDCG Score: 0.40575551427501483\n",
      "{'num_leaves': 120, 'max_depth': 12, 'min_child_samples': 210, 'learning_rate': 0.1, 'feature_fraction': 0.9, 'bagging_fraction': 0.9, 'bagging_freq': 4, 'reg_alpha': 5, 'reg_lambda': 100, 'num_iterations': 400, 'objective': 'lambdarank', 'metric': 'ndcg', 'ndcg_eval_at': [5], 'verbose': -1, 'boosting_type': 'gbdt', 'feature_pre_filter': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/eva/opt/anaconda3/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[332]\tvalid_0's ndcg@5: 0.404906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/st/hfszkgw55n73h3v2jz7n8xth0000gn/T/ipykernel_52975/2751782417.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df['predictions'] = test_pred\n",
      "/var/folders/st/hfszkgw55n73h3v2jz7n8xth0000gn/T/ipykernel_52975/2751782417.py:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df.sort_values(['srch_id', 'predictions'], ascending=[True, False], inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average NDCG Score: 0.4040546206807331\n",
      "{'num_leaves': 110, 'max_depth': 12, 'min_child_samples': 210, 'learning_rate': 0.1, 'feature_fraction': 0.9, 'bagging_fraction': 0.9, 'bagging_freq': 4, 'reg_alpha': 5, 'reg_lambda': 100, 'num_iterations': 400, 'objective': 'lambdarank', 'metric': 'ndcg', 'ndcg_eval_at': [5], 'verbose': -1, 'boosting_type': 'gbdt', 'feature_pre_filter': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/eva/opt/anaconda3/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[276]\tvalid_0's ndcg@5: 0.40443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/st/hfszkgw55n73h3v2jz7n8xth0000gn/T/ipykernel_52975/2751782417.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df['predictions'] = test_pred\n",
      "/var/folders/st/hfszkgw55n73h3v2jz7n8xth0000gn/T/ipykernel_52975/2751782417.py:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df.sort_values(['srch_id', 'predictions'], ascending=[True, False], inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average NDCG Score: 0.40333647850554855\n",
      "{'num_leaves': 120, 'max_depth': 12, 'min_child_samples': 210, 'learning_rate': 0.1, 'feature_fraction': 0.9, 'bagging_fraction': 0.9, 'bagging_freq': 3, 'reg_alpha': 5, 'reg_lambda': 100, 'num_iterations': 400, 'objective': 'lambdarank', 'metric': 'ndcg', 'ndcg_eval_at': [5], 'verbose': -1, 'boosting_type': 'gbdt', 'feature_pre_filter': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/eva/opt/anaconda3/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[322]\tvalid_0's ndcg@5: 0.40484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/st/hfszkgw55n73h3v2jz7n8xth0000gn/T/ipykernel_52975/2751782417.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df['predictions'] = test_pred\n",
      "/var/folders/st/hfszkgw55n73h3v2jz7n8xth0000gn/T/ipykernel_52975/2751782417.py:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df.sort_values(['srch_id', 'predictions'], ascending=[True, False], inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average NDCG Score: 0.40499292155199795\n",
      "Best NDCG Score: 0.4068791481469258\n",
      "Best Parameters: {'num_leaves': 110, 'max_depth': 12, 'min_child_samples': 210, 'learning_rate': 0.1, 'feature_fraction': 0.9, 'bagging_fraction': 0.9, 'bagging_freq': 3, 'reg_alpha': 5, 'reg_lambda': 100, 'num_iterations': 400, 'objective': 'lambdarank', 'metric': 'ndcg', 'ndcg_eval_at': [5], 'verbose': -1, 'boosting_type': 'gbdt', 'feature_pre_filter': False}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'num_leaves': [120,110], 'max_depth': [12], 'min_child_samples': [210], 'learning_rate': [0.1], 'feature_fraction': [0.9], \n",
    "    'bagging_fraction': [0.9], 'bagging_freq': [2,3,4], 'reg_alpha': [5], 'reg_lambda': [100], 'num_iterations': [400], \n",
    "}\n",
    "\n",
    "# random search\n",
    "best_ndcg = 0\n",
    "best_params = None\n",
    "n_iterations = 50  # iterations for random search\n",
    "tested_params = set()\n",
    "\n",
    "for _ in range(n_iterations):\n",
    "    # Generate unique random parameter combination\n",
    "    random_params = {k: random.choice(v) for k, v in param_grid.items()}\n",
    "    param_tuple = tuple(random_params.items())  # Convert to tuple to be hashable\n",
    "    if param_tuple in tested_params:\n",
    "        continue  # Skip this iteration if we've already tested these parameters\n",
    "    tested_params.add(param_tuple)  # Add new parameters to the set\n",
    "\n",
    "    # Additional parameters\n",
    "    random_params.update({\n",
    "        'objective': 'lambdarank',\n",
    "        'metric': 'ndcg',\n",
    "        'ndcg_eval_at': [5],\n",
    "        'verbose': -1,\n",
    "        'boosting_type': 'gbdt',\n",
    "        'feature_pre_filter': False\n",
    "    })\n",
    "\n",
    "    print(random_params)\n",
    "    bst = lgb.train(\n",
    "        random_params,\n",
    "        train_data,\n",
    "        valid_sets=[val_data],\n",
    "        callbacks=[lgb.early_stopping(30)]\n",
    "    )\n",
    "\n",
    "    test_pred = bst.predict(test_df[features], num_iteration=bst.best_iteration)\n",
    "    test_df['predictions'] = test_pred\n",
    "    test_df.sort_values(['srch_id', 'predictions'], ascending=[True, False], inplace=True)\n",
    "    grouped = test_df.groupby('srch_id')\n",
    "    ndcg_scores = []\n",
    "\n",
    "    for name, group in grouped:\n",
    "        true_relevance = group['score'].values\n",
    "        scores_pred = group['predictions'].values\n",
    "        if len(np.unique(true_relevance)) > 1:\n",
    "            ndcg_scores.append(ndcg_score([true_relevance], [scores_pred], k=5))\n",
    "\n",
    "    average_ndcg = np.mean(ndcg_scores)\n",
    "    print(f\"Average NDCG Score: {average_ndcg}\")\n",
    "    if average_ndcg > best_ndcg:\n",
    "        best_ndcg = average_ndcg\n",
    "        best_params = random_params\n",
    "\n",
    "print(f\"Best NDCG Score: {best_ndcg}\")\n",
    "print(\"Best Parameters:\", best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation Result Documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_ids = df['srch_id'].unique()\n",
    "train_ids, test_ids = train_test_split(unique_ids, test_size=0.2, random_state=42, shuffle=True)\n",
    "train_df = df[df['srch_id'].isin(train_ids)]\n",
    "test_df = df[df['srch_id'].isin(test_ids)]\n",
    "\n",
    "\n",
    "# 准备 LightGBM 数据结构\n",
    "train_data = lgb.Dataset(train_df[features], label=train_df['score'], group=train_df['srch_id'].value_counts().sort_index())\n",
    "test_data = lgb.Dataset(test_df[features], label=test_df['score'], group=test_df['srch_id'].value_counts().sort_index())\n",
    "\n",
    "# 设置模型参数\n",
    "params = {'num_leaves': 110, 'max_depth': 12, 'min_child_samples': 210, 'learning_rate': 0.1, 'feature_fraction': 0.9, 'bagging_fraction': 0.9, 'bagging_freq': 3, 'reg_alpha': 10, 'reg_lambda': 100, 'num_iterations': 400, 'objective': 'lambdarank', 'metric': 'ndcg', 'ndcg_eval_at': [5], 'verbose': -1, 'boosting_type': 'gbdt', 'feature_pre_filter': False}\n",
    "\n",
    "# 训练模型\n",
    "num_round = 200\n",
    "bst = lgb.train(params, train_data, num_round, valid_sets=[test_data])\n",
    "\n",
    "lgb.plot_importance(bst, max_num_features=30, importance_type='split', figsize=(10, 15), title='Feature Importance')\n",
    "plt.show()\n",
    "# 预测测试集\n",
    "test_pred = bst.predict(test_df[features])\n",
    "\n",
    "# 评估模型，计算 NDCG 分数\n",
    "test_df['predictions'] = test_pred\n",
    "\n",
    "# 首先确保数据按照 srch_id 和 predictions 降序排序\n",
    "test_df.sort_values(['srch_id', 'predictions'], ascending=[True, False], inplace=True)\n",
    "\n",
    "# 分组并计算每个搜索会话的 NDCG\n",
    "grouped = test_df.groupby('srch_id')\n",
    "ndcg_scores = []\n",
    "\n",
    "for name, group in grouped:\n",
    "    group = group.sort_values('predictions', ascending=False)\n",
    "    true_relevance = group['score'].values\n",
    "    scores_pred = group['predictions'].values\n",
    "    # 计算当前搜索会话的 NDCG 分数，并追加到列表中\n",
    "    if len(np.unique(true_relevance)) > 1:  # 只计算有正样本的会话\n",
    "        ndcg_scores.append(ndcg_score([true_relevance], [scores_pred], k=5))\n",
    "\n",
    "average_ndcg = np.mean(ndcg_scores)\n",
    "print(f\"Average NDCG Score: {average_ndcg}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'num_leaves': 110, 'max_depth': 12, 'min_child_samples': 210, 'learning_rate': 0.1, 'feature_fraction': 0.9, 'bagging_fraction': 0.9, 'bagging_freq': 3, 'reg_alpha': 10, 'reg_lambda': 100, 'num_iterations': 400, 'objective': 'lambdarank', 'metric': 'ndcg', 'ndcg_eval_at': [5], 'verbose': -1, 'boosting_type': 'gbdt', 'feature_pre_filter': False}\n",
    "Average NDCG Score: 0.409272657937892\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance = bst.feature_importance(importance_type='split')\n",
    "feature_names = bst.feature_name()\n",
    "feature_importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': importance})\n",
    "\n",
    "# 按重要性排序\n",
    "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# 保存到CSV文件\n",
    "feature_importance_df.to_csv('feature_importance.csv', index=False)\n",
    "\n",
    "print(feature_importance_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用迭代器逐块读取数据\n",
    "chunk_size = 10000\n",
    "reader = pd.read_csv('/Users/eva/Documents/Study/Y1S2/DMT/assignment2/best_feature_engineered_test_set_VU_DM.csv', chunksize=chunk_size)\n",
    "\n",
    "predictions = []  # 创建一个空列表以存储每个块的预测结果\n",
    "for chunk in reader:\n",
    "    # 可以在这里添加数据预处理步骤，比如填充缺失值等\n",
    "    chunk_pred = bst.predict(chunk[features])  # 应用模型进行预测\n",
    "    chunk['predictions'] = chunk_pred  # 将预测结果添加到 DataFrame\n",
    "    predictions.append(chunk[['srch_id', 'prop_id', 'predictions']])  # 仅保留需要的列\n",
    "\n",
    "# 合并所有批次的预测结果\n",
    "final_predictions = pd.concat(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 确保按照预测分数排序，如果 Kaggle 要求\n",
    "final_predictions.sort_values(['srch_id', 'predictions'], ascending=[True, False], inplace=True)\n",
    "\n",
    "# 选择需要的列\n",
    "final_predictions = final_predictions[['srch_id', 'prop_id']]\n",
    "\n",
    "# 保存为 CSV 文件，确保不包含索引，包含列标题\n",
    "final_predictions.to_csv('train=priyank+menghan_featured_withrank).csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(final_predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
