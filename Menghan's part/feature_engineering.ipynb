{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>srch_id</th>\n",
       "      <th>date_time</th>\n",
       "      <th>site_id</th>\n",
       "      <th>visitor_location_country_id</th>\n",
       "      <th>visitor_hist_starrating</th>\n",
       "      <th>visitor_hist_adr_usd</th>\n",
       "      <th>prop_country_id</th>\n",
       "      <th>prop_id</th>\n",
       "      <th>prop_starrating</th>\n",
       "      <th>prop_review_score</th>\n",
       "      <th>...</th>\n",
       "      <th>comp7_rate</th>\n",
       "      <th>comp7_inv</th>\n",
       "      <th>comp7_rate_percent_diff</th>\n",
       "      <th>comp8_rate</th>\n",
       "      <th>comp8_inv</th>\n",
       "      <th>comp8_rate_percent_diff</th>\n",
       "      <th>click_bool</th>\n",
       "      <th>gross_bookings_usd</th>\n",
       "      <th>booking_bool</th>\n",
       "      <th>bool_visitor_hist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2013-04-04 08:32:15</td>\n",
       "      <td>12</td>\n",
       "      <td>187</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>219</td>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2013-04-04 08:32:15</td>\n",
       "      <td>12</td>\n",
       "      <td>187</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>219</td>\n",
       "      <td>10404</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2013-04-04 08:32:15</td>\n",
       "      <td>12</td>\n",
       "      <td>187</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>219</td>\n",
       "      <td>21315</td>\n",
       "      <td>3</td>\n",
       "      <td>4.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2013-04-04 08:32:15</td>\n",
       "      <td>12</td>\n",
       "      <td>187</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>219</td>\n",
       "      <td>27348</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2013-04-04 08:32:15</td>\n",
       "      <td>12</td>\n",
       "      <td>187</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>219</td>\n",
       "      <td>29604</td>\n",
       "      <td>4</td>\n",
       "      <td>3.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   srch_id            date_time  site_id  visitor_location_country_id  \\\n",
       "0        1  2013-04-04 08:32:15       12                          187   \n",
       "1        1  2013-04-04 08:32:15       12                          187   \n",
       "2        1  2013-04-04 08:32:15       12                          187   \n",
       "3        1  2013-04-04 08:32:15       12                          187   \n",
       "4        1  2013-04-04 08:32:15       12                          187   \n",
       "\n",
       "   visitor_hist_starrating  visitor_hist_adr_usd  prop_country_id  prop_id  \\\n",
       "0                      0.0                   0.0              219      893   \n",
       "1                      0.0                   0.0              219    10404   \n",
       "2                      0.0                   0.0              219    21315   \n",
       "3                      0.0                   0.0              219    27348   \n",
       "4                      0.0                   0.0              219    29604   \n",
       "\n",
       "   prop_starrating  prop_review_score  ...  comp7_rate  comp7_inv  \\\n",
       "0                3                3.5  ...         0.0        0.0   \n",
       "1                4                4.0  ...         0.0        0.0   \n",
       "2                3                4.5  ...         0.0        0.0   \n",
       "3                2                4.0  ...         0.0        0.0   \n",
       "4                4                3.5  ...         0.0        0.0   \n",
       "\n",
       "   comp7_rate_percent_diff  comp8_rate  comp8_inv  comp8_rate_percent_diff  \\\n",
       "0                      0.0         0.0        0.0                      0.0   \n",
       "1                      0.0         0.0        0.0                      0.0   \n",
       "2                      0.0         0.0        0.0                      0.0   \n",
       "3                      0.0        -1.0        0.0                      5.0   \n",
       "4                      0.0         0.0        0.0                      0.0   \n",
       "\n",
       "   click_bool  gross_bookings_usd  booking_bool  bool_visitor_hist  \n",
       "0           0                 0.0             0                  0  \n",
       "1           0                 0.0             0                  0  \n",
       "2           0                 0.0             0                  0  \n",
       "3           0                 0.0             0                  0  \n",
       "4           0                 0.0             0                  0  \n",
       "\n",
       "[5 rows x 55 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"/Users/eva/Documents/Study/Y1S2/DMT/assignment2/cleaned_training_set_VU_DM.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(\"/Users/eva/Documents/Study/Y1S2/DMT/assignment2/cleaned_test_set_VU_DM.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "# print columns with NA in df and df_test \n",
    "print(df.columns[df.isnull().any()].tolist())\n",
    "print(df_test.columns[df_test.isnull().any()].tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4958347\n",
      "4959183\n"
     ]
    }
   ],
   "source": [
    "#print df and df_test length\n",
    "print(len(df))\n",
    "print(len(df_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find columns with numeric values so that we can caluculate mean, std, median per prop_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = pd.concat([df, df_test], ignore_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "bool_flag_cols = [col for col in combined_df.columns if 'bool' in col.lower() or 'flag' in col.lower()]\n",
    "\n",
    "# transform the columns to boolean\n",
    "for col in bool_flag_cols:\n",
    "    combined_df[col] = combined_df[col].astype(bool)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "object\n"
     ]
    }
   ],
   "source": [
    "print(combined_df['date_time'].dtypes)\n",
    "# transform it into datetime\n",
    "combined_df['date_time'] = pd.to_datetime(combined_df['date_time'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['comp1_rate', 'comp2_rate', 'comp3_rate', 'comp4_rate', 'comp5_rate',\n",
      "       'comp6_rate', 'comp7_rate', 'comp8_rate'],\n",
      "      dtype='object')\n",
      "['comp1_inv', 'comp2_inv', 'comp3_inv', 'comp4_inv', 'comp5_inv', 'comp6_inv', 'comp7_inv', 'comp8_inv']\n"
     ]
    }
   ],
   "source": [
    "# print columns end with rate and env\n",
    "rate_cols = combined_df.columns[combined_df.columns.str.endswith('rate')]\n",
    "inv_cols = [col for col in combined_df.columns if 'inv' in col.lower()]\n",
    "print(rate_cols)\n",
    "print(inv_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['visitor_hist_starrating', 'visitor_hist_adr_usd', 'prop_starrating', 'prop_review_score', 'prop_location_score1', 'prop_location_score2', 'prop_log_historical_price', 'position', 'price_usd', 'srch_length_of_stay', 'srch_booking_window', 'srch_adults_count', 'srch_children_count', 'srch_room_count', 'srch_query_affinity_score', 'orig_destination_distance', 'comp1_rate_percent_diff', 'comp2_rate_percent_diff', 'comp3_rate_percent_diff', 'comp4_rate_percent_diff', 'comp5_rate_percent_diff', 'comp6_rate_percent_diff', 'comp7_rate_percent_diff', 'comp8_rate_percent_diff', 'gross_bookings_usd']\n",
      "25\n"
     ]
    }
   ],
   "source": [
    "numeric_cols = [col for col in combined_df.select_dtypes(include=['int64', 'float64']).columns if 'id' not in col and col not in rate_cols and col not in inv_cols]\n",
    "print(numeric_cols)\n",
    "print(len(numeric_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/st/hfszkgw55n73h3v2jz7n8xth0000gn/T/ipykernel_2878/2445899447.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[column_name] = grouped[feature].transform(stat)\n",
      "/var/folders/st/hfszkgw55n73h3v2jz7n8xth0000gn/T/ipykernel_2878/2445899447.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[column_name] = grouped[feature].transform(stat)\n",
      "/var/folders/st/hfszkgw55n73h3v2jz7n8xth0000gn/T/ipykernel_2878/2445899447.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[column_name] = grouped[feature].transform(stat)\n",
      "/var/folders/st/hfszkgw55n73h3v2jz7n8xth0000gn/T/ipykernel_2878/2445899447.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[column_name] = grouped[feature].transform(stat)\n",
      "/var/folders/st/hfszkgw55n73h3v2jz7n8xth0000gn/T/ipykernel_2878/2445899447.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[column_name] = grouped[feature].transform(stat)\n",
      "/var/folders/st/hfszkgw55n73h3v2jz7n8xth0000gn/T/ipykernel_2878/2445899447.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[column_name] = grouped[feature].transform(stat)\n",
      "/var/folders/st/hfszkgw55n73h3v2jz7n8xth0000gn/T/ipykernel_2878/2445899447.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[column_name] = grouped[feature].transform(stat)\n",
      "/var/folders/st/hfszkgw55n73h3v2jz7n8xth0000gn/T/ipykernel_2878/2445899447.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[column_name] = grouped[feature].transform(stat)\n",
      "/var/folders/st/hfszkgw55n73h3v2jz7n8xth0000gn/T/ipykernel_2878/2445899447.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[column_name] = grouped[feature].transform(stat)\n",
      "/var/folders/st/hfszkgw55n73h3v2jz7n8xth0000gn/T/ipykernel_2878/2445899447.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[column_name] = grouped[feature].transform(stat)\n",
      "/var/folders/st/hfszkgw55n73h3v2jz7n8xth0000gn/T/ipykernel_2878/2445899447.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[column_name] = grouped[feature].transform(stat)\n",
      "/var/folders/st/hfszkgw55n73h3v2jz7n8xth0000gn/T/ipykernel_2878/2445899447.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[column_name] = grouped[feature].transform(stat)\n",
      "/var/folders/st/hfszkgw55n73h3v2jz7n8xth0000gn/T/ipykernel_2878/2445899447.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[column_name] = grouped[feature].transform(stat)\n",
      "/var/folders/st/hfszkgw55n73h3v2jz7n8xth0000gn/T/ipykernel_2878/2445899447.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[column_name] = grouped[feature].transform(stat)\n",
      "/var/folders/st/hfszkgw55n73h3v2jz7n8xth0000gn/T/ipykernel_2878/2445899447.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[column_name] = grouped[feature].transform(stat)\n",
      "/var/folders/st/hfszkgw55n73h3v2jz7n8xth0000gn/T/ipykernel_2878/2445899447.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[column_name] = grouped[feature].transform(stat)\n",
      "/var/folders/st/hfszkgw55n73h3v2jz7n8xth0000gn/T/ipykernel_2878/2445899447.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[column_name] = grouped[feature].transform(stat)\n",
      "/var/folders/st/hfszkgw55n73h3v2jz7n8xth0000gn/T/ipykernel_2878/2445899447.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[column_name] = grouped[feature].transform(stat)\n",
      "/var/folders/st/hfszkgw55n73h3v2jz7n8xth0000gn/T/ipykernel_2878/2445899447.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[column_name] = grouped[feature].transform(stat)\n",
      "/var/folders/st/hfszkgw55n73h3v2jz7n8xth0000gn/T/ipykernel_2878/2445899447.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[column_name] = grouped[feature].transform(stat)\n",
      "/var/folders/st/hfszkgw55n73h3v2jz7n8xth0000gn/T/ipykernel_2878/2445899447.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[column_name] = grouped[feature].transform(stat)\n",
      "/var/folders/st/hfszkgw55n73h3v2jz7n8xth0000gn/T/ipykernel_2878/2445899447.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[column_name] = grouped[feature].transform(stat)\n",
      "/var/folders/st/hfszkgw55n73h3v2jz7n8xth0000gn/T/ipykernel_2878/2445899447.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[column_name] = grouped[feature].transform(stat)\n",
      "/var/folders/st/hfszkgw55n73h3v2jz7n8xth0000gn/T/ipykernel_2878/2445899447.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[column_name] = grouped[feature].transform(stat)\n",
      "/var/folders/st/hfszkgw55n73h3v2jz7n8xth0000gn/T/ipykernel_2878/2445899447.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[column_name] = grouped[feature].transform(stat)\n",
      "/var/folders/st/hfszkgw55n73h3v2jz7n8xth0000gn/T/ipykernel_2878/2445899447.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[column_name] = grouped[feature].transform(stat)\n",
      "/var/folders/st/hfszkgw55n73h3v2jz7n8xth0000gn/T/ipykernel_2878/2445899447.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[column_name] = grouped[feature].transform(stat)\n",
      "/var/folders/st/hfszkgw55n73h3v2jz7n8xth0000gn/T/ipykernel_2878/2445899447.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[column_name] = grouped[feature].transform(stat)\n",
      "/var/folders/st/hfszkgw55n73h3v2jz7n8xth0000gn/T/ipykernel_2878/2445899447.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[column_name] = grouped[feature].transform(stat)\n",
      "/var/folders/st/hfszkgw55n73h3v2jz7n8xth0000gn/T/ipykernel_2878/2445899447.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[column_name] = grouped[feature].transform(stat)\n",
      "/var/folders/st/hfszkgw55n73h3v2jz7n8xth0000gn/T/ipykernel_2878/2445899447.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[column_name] = grouped[feature].transform(stat)\n",
      "/var/folders/st/hfszkgw55n73h3v2jz7n8xth0000gn/T/ipykernel_2878/2445899447.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[column_name] = grouped[feature].transform(stat)\n",
      "/var/folders/st/hfszkgw55n73h3v2jz7n8xth0000gn/T/ipykernel_2878/2445899447.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[column_name] = grouped[feature].transform(stat)\n",
      "/var/folders/st/hfszkgw55n73h3v2jz7n8xth0000gn/T/ipykernel_2878/2445899447.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[column_name] = grouped[feature].transform(stat)\n",
      "/var/folders/st/hfszkgw55n73h3v2jz7n8xth0000gn/T/ipykernel_2878/2445899447.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[column_name] = grouped[feature].transform(stat)\n",
      "/var/folders/st/hfszkgw55n73h3v2jz7n8xth0000gn/T/ipykernel_2878/2445899447.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[column_name] = grouped[feature].transform(stat)\n",
      "/var/folders/st/hfszkgw55n73h3v2jz7n8xth0000gn/T/ipykernel_2878/2445899447.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[column_name] = grouped[feature].transform(stat)\n",
      "/var/folders/st/hfszkgw55n73h3v2jz7n8xth0000gn/T/ipykernel_2878/2445899447.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[column_name] = grouped[feature].transform(stat)\n",
      "/var/folders/st/hfszkgw55n73h3v2jz7n8xth0000gn/T/ipykernel_2878/2445899447.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[column_name] = grouped[feature].transform(stat)\n",
      "/var/folders/st/hfszkgw55n73h3v2jz7n8xth0000gn/T/ipykernel_2878/2445899447.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[column_name] = grouped[feature].transform(stat)\n",
      "/var/folders/st/hfszkgw55n73h3v2jz7n8xth0000gn/T/ipykernel_2878/2445899447.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[column_name] = grouped[feature].transform(stat)\n",
      "/var/folders/st/hfszkgw55n73h3v2jz7n8xth0000gn/T/ipykernel_2878/2445899447.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[column_name] = grouped[feature].transform(stat)\n",
      "/var/folders/st/hfszkgw55n73h3v2jz7n8xth0000gn/T/ipykernel_2878/2445899447.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[column_name] = grouped[feature].transform(stat)\n",
      "/var/folders/st/hfszkgw55n73h3v2jz7n8xth0000gn/T/ipykernel_2878/2445899447.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[column_name] = grouped[feature].transform(stat)\n",
      "/var/folders/st/hfszkgw55n73h3v2jz7n8xth0000gn/T/ipykernel_2878/2445899447.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[column_name] = grouped[feature].transform(stat)\n",
      "/var/folders/st/hfszkgw55n73h3v2jz7n8xth0000gn/T/ipykernel_2878/2445899447.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[column_name] = grouped[feature].transform(stat)\n",
      "/var/folders/st/hfszkgw55n73h3v2jz7n8xth0000gn/T/ipykernel_2878/2445899447.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[column_name] = grouped[feature].transform(stat)\n",
      "/var/folders/st/hfszkgw55n73h3v2jz7n8xth0000gn/T/ipykernel_2878/2445899447.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[column_name] = grouped[feature].transform(stat)\n",
      "/var/folders/st/hfszkgw55n73h3v2jz7n8xth0000gn/T/ipykernel_2878/2445899447.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[column_name] = grouped[feature].transform(stat)\n",
      "/var/folders/st/hfszkgw55n73h3v2jz7n8xth0000gn/T/ipykernel_2878/2445899447.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[column_name] = grouped[feature].transform(stat)\n",
      "/var/folders/st/hfszkgw55n73h3v2jz7n8xth0000gn/T/ipykernel_2878/2445899447.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[column_name] = grouped[feature].transform(stat)\n",
      "/var/folders/st/hfszkgw55n73h3v2jz7n8xth0000gn/T/ipykernel_2878/2445899447.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[column_name] = grouped[feature].transform(stat)\n",
      "/var/folders/st/hfszkgw55n73h3v2jz7n8xth0000gn/T/ipykernel_2878/2445899447.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[column_name] = grouped[feature].transform(stat)\n",
      "/var/folders/st/hfszkgw55n73h3v2jz7n8xth0000gn/T/ipykernel_2878/2445899447.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[column_name] = grouped[feature].transform(stat)\n",
      "/var/folders/st/hfszkgw55n73h3v2jz7n8xth0000gn/T/ipykernel_2878/2445899447.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[column_name] = grouped[feature].transform(stat)\n",
      "/var/folders/st/hfszkgw55n73h3v2jz7n8xth0000gn/T/ipykernel_2878/2445899447.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[column_name] = grouped[feature].transform(stat)\n",
      "/var/folders/st/hfszkgw55n73h3v2jz7n8xth0000gn/T/ipykernel_2878/2445899447.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[column_name] = grouped[feature].transform(stat)\n",
      "/var/folders/st/hfszkgw55n73h3v2jz7n8xth0000gn/T/ipykernel_2878/2445899447.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[column_name] = grouped[feature].transform(stat)\n",
      "/var/folders/st/hfszkgw55n73h3v2jz7n8xth0000gn/T/ipykernel_2878/2445899447.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[column_name] = grouped[feature].transform(stat)\n",
      "/var/folders/st/hfszkgw55n73h3v2jz7n8xth0000gn/T/ipykernel_2878/2445899447.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[column_name] = grouped[feature].transform(stat)\n",
      "/var/folders/st/hfszkgw55n73h3v2jz7n8xth0000gn/T/ipykernel_2878/2445899447.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[column_name] = grouped[feature].transform(stat)\n",
      "/var/folders/st/hfszkgw55n73h3v2jz7n8xth0000gn/T/ipykernel_2878/2445899447.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[column_name] = grouped[feature].transform(stat)\n",
      "/var/folders/st/hfszkgw55n73h3v2jz7n8xth0000gn/T/ipykernel_2878/2445899447.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[column_name] = grouped[feature].transform(stat)\n",
      "/var/folders/st/hfszkgw55n73h3v2jz7n8xth0000gn/T/ipykernel_2878/2445899447.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[column_name] = grouped[feature].transform(stat)\n",
      "/var/folders/st/hfszkgw55n73h3v2jz7n8xth0000gn/T/ipykernel_2878/2445899447.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[column_name] = grouped[feature].transform(stat)\n",
      "/var/folders/st/hfszkgw55n73h3v2jz7n8xth0000gn/T/ipykernel_2878/2445899447.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[column_name] = grouped[feature].transform(stat)\n",
      "/var/folders/st/hfszkgw55n73h3v2jz7n8xth0000gn/T/ipykernel_2878/2445899447.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[column_name] = grouped[feature].transform(stat)\n",
      "/var/folders/st/hfszkgw55n73h3v2jz7n8xth0000gn/T/ipykernel_2878/2445899447.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[column_name] = grouped[feature].transform(stat)\n",
      "/var/folders/st/hfszkgw55n73h3v2jz7n8xth0000gn/T/ipykernel_2878/2445899447.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[column_name] = grouped[feature].transform(stat)\n",
      "/var/folders/st/hfszkgw55n73h3v2jz7n8xth0000gn/T/ipykernel_2878/2445899447.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[column_name] = grouped[feature].transform(stat)\n",
      "/var/folders/st/hfszkgw55n73h3v2jz7n8xth0000gn/T/ipykernel_2878/2445899447.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[column_name] = grouped[feature].transform(stat)\n",
      "/var/folders/st/hfszkgw55n73h3v2jz7n8xth0000gn/T/ipykernel_2878/2445899447.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[column_name] = grouped[feature].transform(stat)\n",
      "/var/folders/st/hfszkgw55n73h3v2jz7n8xth0000gn/T/ipykernel_2878/2445899447.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df[column_name] = grouped[feature].transform(stat)\n"
     ]
    }
   ],
   "source": [
    "features = ['visitor_hist_starrating', 'visitor_hist_adr_usd', 'prop_starrating', 'prop_review_score', 'prop_location_score1', \n",
    "            'prop_location_score2', 'prop_log_historical_price', 'price_usd', 'srch_length_of_stay', 'srch_booking_window', \n",
    "            'srch_adults_count', 'srch_children_count', 'srch_room_count', 'srch_query_affinity_score', 'orig_destination_distance', \n",
    "            'comp1_rate_percent_diff', 'comp2_rate_percent_diff']\n",
    "\n",
    "\n",
    "# 计算每个组合的均值、中位数和标准差\n",
    "grouped = combined_df.groupby(['prop_id', 'srch_id', 'srch_destination_id'])\n",
    "stats = grouped[features].agg(['mean', 'median', 'std'])\n",
    "\n",
    "original_train_len = len(df)\n",
    "original_test_len = len(df_test)\n",
    "for feature in features:\n",
    "    for id_col in ['prop_id', 'srch_id', 'srch_destination_id']:\n",
    "        for stat in ['mean', 'median', 'std']:\n",
    "            column_name = f'{feature}_{id_col}_{stat}'\n",
    "            combined_df[column_name] = grouped[feature].transform(stat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/st/hfszkgw55n73h3v2jz7n8xth0000gn/T/ipykernel_2878/1980084526.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df['price_diff'] = combined_df['price_usd'] - combined_df['price_usd_srch_id_median']\n",
      "/var/folders/st/hfszkgw55n73h3v2jz7n8xth0000gn/T/ipykernel_2878/1980084526.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df['prop_location_score1_diff'] = combined_df['prop_location_score1'] - combined_df['prop_location_score1_srch_id_median']\n",
      "/var/folders/st/hfszkgw55n73h3v2jz7n8xth0000gn/T/ipykernel_2878/1980084526.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df['prop_location_score2_diff'] = combined_df['prop_location_score2'] - combined_df['prop_location_score2_srch_id_median']\n",
      "/var/folders/st/hfszkgw55n73h3v2jz7n8xth0000gn/T/ipykernel_2878/1980084526.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df['prop_review_score_diff'] = combined_df['prop_review_score'] - combined_df['prop_review_score_srch_id_median']\n",
      "/var/folders/st/hfszkgw55n73h3v2jz7n8xth0000gn/T/ipykernel_2878/1980084526.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df['prop_starrating_diff'] = combined_df['prop_starrating'] - combined_df['prop_starrating_srch_id_median']\n",
      "/var/folders/st/hfszkgw55n73h3v2jz7n8xth0000gn/T/ipykernel_2878/1980084526.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df['price_per_adult'] = combined_df['price_usd'] / combined_df['srch_adults_count']\n",
      "/var/folders/st/hfszkgw55n73h3v2jz7n8xth0000gn/T/ipykernel_2878/1980084526.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df['price_per_person'] = combined_df['price_usd'] / (combined_df['srch_adults_count'] + combined_df['srch_children_count'])\n",
      "/var/folders/st/hfszkgw55n73h3v2jz7n8xth0000gn/T/ipykernel_2878/1980084526.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df['prop_historical_price'] = np.exp(combined_df['prop_log_historical_price'])\n",
      "/var/folders/st/hfszkgw55n73h3v2jz7n8xth0000gn/T/ipykernel_2878/1980084526.py:24: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df['prop_clicked_prob'] = 10 ** combined_df['srch_query_affinity_score']\n",
      "/var/folders/st/hfszkgw55n73h3v2jz7n8xth0000gn/T/ipykernel_2878/1980084526.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df['child_bool'] = combined_df['srch_children_count'] > 0\n"
     ]
    }
   ],
   "source": [
    "# add a column to compute the price difference in each srch_id group(compared with the median one)\n",
    "combined_df['price_diff'] = combined_df['price_usd'] - combined_df['price_usd_srch_id_median']\n",
    "\n",
    "# add a column to compute prop_location_score1 difference in each srch_id group(compared with the median one)\n",
    "combined_df['prop_location_score1_diff'] = combined_df['prop_location_score1'] - combined_df['prop_location_score1_srch_id_median']\n",
    "\n",
    "# add a column to compute prop_location_score2 difference in each srch_id group(compared with the median one)\n",
    "combined_df['prop_location_score2_diff'] = combined_df['prop_location_score2'] - combined_df['prop_location_score2_srch_id_median']\n",
    "\n",
    "# add a column to compute review score difference in each srch_id group(compared with the median one)\n",
    "combined_df['prop_review_score_diff'] = combined_df['prop_review_score'] - combined_df['prop_review_score_srch_id_median']\n",
    "\n",
    "# add a column to compute prop_starrating_diff in each srch_id group(compared with the median one)\n",
    "combined_df['prop_starrating_diff'] = combined_df['prop_starrating'] - combined_df['prop_starrating_srch_id_median']\n",
    "\n",
    "# add columns to compute price per adult and price per person\n",
    "combined_df['price_per_adult'] = combined_df['price_usd'] / combined_df['srch_adults_count']\n",
    "combined_df['price_per_person'] = combined_df['price_usd'] / (combined_df['srch_adults_count'] + combined_df['srch_children_count'])\n",
    "\n",
    "# add prop_historical_price\n",
    "combined_df['prop_historical_price'] = np.exp(combined_df['prop_log_historical_price'])\n",
    "\n",
    "# add prop_clicked_prob by taking 10 to the power of “srch query affinity score”\n",
    "combined_df['prop_clicked_prob'] = 10 ** combined_df['srch_query_affinity_score']\n",
    "\n",
    "# add child or not bool\n",
    "combined_df['child_bool'] = combined_df['srch_children_count'] > 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = combined_df.iloc[:original_train_len]\n",
    "df_test = combined_df.iloc[original_train_len:original_train_len + original_test_len]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "na_std_cols = [col for col in df.columns if 'std' in col and df[col].isna().any()]\n",
    "df.loc[:, na_std_cols] = df.loc[:, na_std_cols].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "# print columns with NA in df\n",
    "print(df.columns[df.isnull().any()].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "na_std_cols = [col for col in df_test.columns if 'std' in col and df_test[col].isna().any()]\n",
    "df_test.loc[:, na_std_cols] = df_test.loc[:, na_std_cols].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['position', 'gross_bookings_usd']\n"
     ]
    }
   ],
   "source": [
    "# print columns with NA in df_test\n",
    "print(df_test.columns[df_test.isnull().any()].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete columns with NA in df_test\n",
    "df_test = df_test.dropna(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to_csv\n",
    "df.to_csv('/Users/eva/Documents/Study/Y1S2/DMT/assignment2/feature_engineered_training_set_VU_DM.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.to_csv('/Users/eva/Documents/Study/Y1S2/DMT/assignment2/feature_engineered_test_set_VU_DM.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4959183\n",
      "4958347\n"
     ]
    }
   ],
   "source": [
    "# print df_test length\n",
    "print(len(df_test))\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# truncate into chunks\n",
    "# Load the large CSV file\n",
    "file_path = '/Users/eva/Documents/Study/Y1S2/DMT/assignment2/feature_engineered_training_set_VU_DM.csv'\n",
    "# Define the size of each chunk\n",
    "chunk_size = 500000  # This number can change \n",
    "\n",
    "# Split the CSV into chunks\n",
    "for i in range(0, len(df), chunk_size):\n",
    "    chunk = df.iloc[i:i + chunk_size]\n",
    "    chunk.to_csv(f'/Users/eva/Documents/Study/Y1S2/DMT/assignment2/feature_engineered_training_chunk_{i//chunk_size}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# truncate into chunks\n",
    "# Load the large CSV file\n",
    "file_path = '/Users/eva/Documents/Study/Y1S2/DMT/assignment2/feature_engineered_training_set_VU_DM.csv'\n",
    "# Define the size of each chunk\n",
    "chunk_size = 500000  # This number can change \n",
    "\n",
    "# Split the CSV into chunks\n",
    "for i in range(0, len(df_test), chunk_size):\n",
    "    chunk = df_test.iloc[i:i + chunk_size]\n",
    "    chunk.to_csv(f'/Users/eva/Documents/Study/Y1S2/DMT/assignment2/feature_engineered_test_chunk_{i//chunk_size}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f'/Users/eva/Documents/Study/Y1S2/DMT/assignment2/feature_engineered_training_chunk_0.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "218\n"
     ]
    }
   ],
   "source": [
    "#print number of df columns\n",
    "print(len(combined_df.columns))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "# check the NA values columns number\n",
    "na_cols = combined_df.columns[combined_df.isna().any()].tolist()\n",
    "print(len(na_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['srch_id', 'date_time', 'site_id', 'visitor_location_country_id',\n",
      "       'visitor_hist_starrating', 'visitor_hist_adr_usd', 'prop_country_id',\n",
      "       'prop_id', 'prop_starrating', 'prop_review_score',\n",
      "       ...\n",
      "       'price_diff', 'prop_location_score1_diff', 'prop_location_score2_diff',\n",
      "       'prop_review_score_diff', 'prop_starrating_diff', 'price_per_adult',\n",
      "       'price_per_person', 'prop_historical_price', 'prop_clicked_prob',\n",
      "       'child_bool'],\n",
      "      dtype='object', length=218)\n"
     ]
    }
   ],
   "source": [
    "# print df columns names\n",
    "print(df.columns)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
